{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def indicator_fill(df):\n",
    "    a = ta.trend.ema_indicator(close=df.Close,window=5)\n",
    "    f = ta.trend.sma_indicator(close=df.Close,window=50)\n",
    "    g = ta.trend.sma_indicator(close=df.candle_sign,window=20)\n",
    "    i = ta.trend.sma_indicator(close=df.Close,window=20)\n",
    "    k = ta.trend.sma_indicator(close=df.Close,window=10)\n",
    "    ssl_high = ta.trend.sma_indicator(close=df.High,window=100)\n",
    "    ssl_low = ta.trend.sma_indicator(close=df.Low,window=100)\n",
    "    l = ta.trend.ichimoku_base_line(high=df.High,low=df.Low)\n",
    "    m = ta.trend.ichimoku_conversion_line(high=df.High,low=df.Low)\n",
    "    h = ta.trend.sma_indicator(close=df.ADF,window=20)\n",
    "    j = ta.trend.sma_indicator(close=df.dur,window=20)\n",
    "    v = ta.volume.chaikin_money_flow(high=df.High,low=df.Low,close=df.Close,volume=df.Volumer)\n",
    "    c = ta.volatility.average_true_range(high=df.High,low=df.Low,close=df.Close)\n",
    "    df[\"5_EMA\"] = a\n",
    "    df[\"50_SMA\"] = f\n",
    "    df[\"20_SMA\"] = i\n",
    "    df[\"10_SMA\"] = k\n",
    "    df[\"candle_sign_agg\"] = g\n",
    "    df[\"ATR\"] = c\n",
    "    df[\"ADF_MA\"] = h\n",
    "    df[\"DUR_MA\"] = j\n",
    "    df[\"kijun\"] = l\n",
    "    df[\"tenkan\"] = m\n",
    "    df[\"chaikin\"] = v\n",
    "    df[\"ssl_high\"] = ssl_high\n",
    "    df[\"ssl_low\"] = ssl_low\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_shadow(opener, close, high):\n",
    "    if opener >= close:\n",
    "        return abs(opener-high)\n",
    "    else:\n",
    "        return abs(close-high)\n",
    "\n",
    "def lower_shadow(opener, close, low):\n",
    "    if opener <= close:\n",
    "        return abs(opener-low)\n",
    "    else:\n",
    "        return abs(close-low)\n",
    "\n",
    "def real_body(opener, close):\n",
    "    return abs(opener-close)\n",
    "\n",
    "def candle_preprocess(df):\n",
    "\n",
    "    df[\"rb\"] = df.apply(lambda x: real_body(x.Open,x.Close), axis = 1)\n",
    "    df[\"us\"] = df.apply(lambda x: upper_shadow(x.Open,x.Close,x.High), axis = 1)\n",
    "    df[\"ls\"] = df.apply(lambda x: lower_shadow(x.Open,x.Close,x.Low), axis = 1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fracdiff import FracdiffStat\n",
    "import pickle\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "def frac_diff_calc(df):\n",
    "    from joblib import load\n",
    "    f = load('frac_diff_SPX.DAT')\n",
    "    at_f = load('frac_diff_SPX_ATR.DAT')\n",
    "    df = df[50:]\n",
    "    c = np.array(df.Close).reshape(-1,1)\n",
    "    e = np.array(df[\"5_EMA\"]).reshape(-1,1)\n",
    "    s = np.array(df[\"50_SMA\"]).reshape(-1,1)\n",
    "    k = np.array(df[\"20_SMA\"]).reshape(-1,1)\n",
    "    a = np.array(df[\"ATR\"]).reshape(-1,1)\n",
    "    df[\"Close\"] = list(np.squeeze(f.transform(c), axis = 1))\n",
    "    df[\"5_EMA\"] = list(np.squeeze(f.transform(e), axis = 1))\n",
    "    df[\"50_SMA\"] = list(np.squeeze(f.transform(s), axis = 1))\n",
    "    df[\"20_SMA\"] = list(np.squeeze(f.transform(k), axis = 1))\n",
    "    df[\"ATR\"] = list(np.squeeze(at_f.transform(a), axis = 1))\n",
    "    df = df[1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_vectorize(df):\n",
    "    vec_load = []\n",
    "    side = []\n",
    "    meta = []\n",
    "    buff_df = df[len(df)-50:len(df)]\n",
    "    close_log = buff_df.Close.tolist()\n",
    "    tick_adf = buff_df.ADF.tolist()\n",
    "    adf_ma = buff_df.ADF_MA.tolist()\n",
    "    c_adf = buff_df.Candle_ADF.tolist()\n",
    "    tick_sign = buff_df.tick_sign_agg.tolist()\n",
    "    candle_sign = buff_df.candle_sign_agg.tolist()\n",
    "    c_sign = buff_df.candle_sign.tolist()\n",
    "    rb_vec = buff_df.rb.tolist()\n",
    "    us_vec = buff_df.us.tolist()\n",
    "    ls_vec = buff_df.ls.tolist()\n",
    "    ema_5 = buff_df[\"5_EMA\"].tolist()\n",
    "    sma_50 = buff_df[\"50_SMA\"].tolist()\n",
    "    sma_20 = buff_df[\"20_SMA\"].tolist()\n",
    "    dur = buff_df.dur.tolist()\n",
    "    dur_ma = buff_df.DUR_MA.tolist()\n",
    "    # interaction features ###############################################################\n",
    "    ma_diff = list(np.array(ema_5)-np.array(sma_50))\n",
    "    ma_20_diff = list(np.array(ema_5)-np.array(sma_20))\n",
    "    close_diff = list(np.array(close_log)-np.array(sma_50))\n",
    "    atr_vec = list(np.array(buff_df.ATR.tolist()) * np.array(close_log))\n",
    "    tick_close_interact = list(np.array(tick_sign) * np.array(close_log))\n",
    "    candle_sign_ma_interact = list(np.array(candle_sign) * np.array(sma_50))\n",
    "    c_sign_close_interact = list(np.array(c_sign) * np.array(close_log))\n",
    "    # This 50 lookback v4\n",
    "    #vec_load += [tick_adf + tick_sign + c_sign + rb_vec + us_vec + ls_vec]\n",
    "    # This 200 lookback v3\n",
    "    vec_load += [tick_adf + c_adf + tick_sign + candle_sign + rb_vec + us_vec + ls_vec\n",
    "                + ma_diff + close_diff + atr_vec + adf_ma]\n",
    "    # This v4\n",
    "    #vec_load += [close_log + tick_adf + c_adf + tick_sign + candle_sign + rb_vec + us_vec + ls_vec + ema_5 + sma_50\n",
    "    #            + ma_diff + close_diff + atr_vec + adf_ma + tick_close_interact + candle_sign_ma_interact]\n",
    "    #vec_load += [close_log + tick_adf + c_adf + tick_sign + candle_sign + rb_vec + us_vec + ls_vec + ema_5 + sma_50 + sma_20\n",
    "    #            + ma_diff + ma_20_diff + close_diff + atr_vec + adf_ma + tick_close_interact + candle_sign_ma_interact]\n",
    "    #vec_load += [c_adf + tick_sign + rb_vec + us_vec + ls_vec + ema_5 + sma_50\n",
    "    #            + ma_diff + close_diff + adf_ma]\n",
    "    #vec_load += [close_log + tick_sign + rb_vec + us_vec + ls_vec + ema_5 + sma_50\n",
    "    #            + sma_20]\n",
    "    return vec_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "trade_df = pd.DataFrame({\"a\":[2]})\n",
    "trade_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\trade_spx.csv\",index=False)\n",
    "close_df = pd.DataFrame({\"a\":[2]})\n",
    "close_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\closure_spx.csv\",index=False)\n",
    "ind_df = pd.DataFrame({\"Ind\":[0]})\n",
    "ind_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\F354DCCD667FB40D8D6DE5A4406D8652\\MQL4\\Files\\load_ind_spx.csv\",index=False)\n",
    "opener = []\n",
    "high = []\n",
    "low = []\n",
    "close = []\n",
    "volume = []\n",
    "tick_adf = []\n",
    "candle_adf = []\n",
    "sign_agg = []\n",
    "pos_run_agg = []\n",
    "counter = 0\n",
    "candle_form = 0\n",
    "dt = datetime.datetime.now()\n",
    "dur = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ta\n",
    "import time\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "model_1 = load(\"200_lookback_fracdiff_side_prediction_xgbclasser_interaction_features_SPX_v3.model\")\n",
    "\n",
    "u=2\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        ind_df = pd.read_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\F354DCCD667FB40D8D6DE5A4406D8652\\MQL4\\Files\\load_ind_spx.csv\", sep=\";\",names=[\"Ind\"])\n",
    "    except:\n",
    "        continue\n",
    "    if ind_df.Ind.tolist()[0] == 1:\n",
    "        try:\n",
    "            df = pd.read_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\F354DCCD667FB40D8D6DE5A4406D8652\\MQL4\\Files\\your_data_spx.csv\",sep=\";\", names=[\"Price\"])\n",
    "        except:\n",
    "            continue\n",
    "        ind_df = pd.DataFrame({\"Ind\":[0]})\n",
    "        ind_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\F354DCCD667FB40D8D6DE5A4406D8652\\MQL4\\Files\\load_ind_spx.csv\",index=False)\n",
    "        \n",
    "        neg_run_agg = []\n",
    "        price = df.Price.tolist()\n",
    "        buff = 0\n",
    "        start = 0\n",
    "        neg_run = 0\n",
    "        pos_run = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        prev = True\n",
    "        for i in range(len(price)):\n",
    "            #buff += (doll[i]*vol[i])\n",
    "            buff += 1\n",
    "            if buff>=100:\n",
    "                clear_output(wait=True)\n",
    "                opener += [price[start]]\n",
    "                high += [max(price[start:i+1])]\n",
    "                low += [min(price[start:i+1])]\n",
    "                close += [price[i]]\n",
    "                tick_adf += [adfuller(price[start:i+1])[1]]\n",
    "                dur += [(datetime.datetime.now()-dt).total_seconds()]\n",
    "                dt = datetime.datetime.now()\n",
    "                counter += 1\n",
    "                print(len(close))\n",
    "                if counter >= 20:\n",
    "                    candle_adf += [adfuller(close[counter-20:counter])[1]]\n",
    "                else:\n",
    "                    candle_adf += [\"pass\"]\n",
    "                if len(close) > 1:\n",
    "                    if close[-1] < close[-2]:\n",
    "                        sign_agg += [-1]\n",
    "                        prev = False\n",
    "                    elif price[-1] > price[-2]:\n",
    "                        sign_agg += [1]\n",
    "                        prev = True\n",
    "                    elif prev:\n",
    "                        sign_agg += [1]\n",
    "                    else:\n",
    "                        sign_agg += [-1]\n",
    "                else:\n",
    "                    sign_agg += [1]\n",
    "                for k in range(start+1,i+1):\n",
    "                    if price[k] < price[k-1]:\n",
    "                        pos_run -= 1\n",
    "                        prev = False\n",
    "                    elif price[k] > price[k-1]:\n",
    "                        pos_run += 1\n",
    "                        prev = True\n",
    "                    elif prev:\n",
    "                        pos_run += 1\n",
    "                    else:\n",
    "                        pos_run -= 1\n",
    "                pos_run_agg += [pos_run/100.0]\n",
    "                start = i+1\n",
    "                buff = 0\n",
    "\n",
    "\n",
    "\n",
    "    if len(close) > 110:\n",
    "        volumer = [200] * len(close)\n",
    "        candle_form = 1\n",
    "        candle_data = pd.DataFrame({\"Volumer\":volumer,\"Open\":opener,\"High\":high,\"Low\":low,\"Close\":close,\"ADF\":tick_adf,\"Candle_ADF\":candle_adf,\"tick_sign_agg\":pos_run_agg,\"candle_sign\":sign_agg,\"dur\":dur})\n",
    "        candle_data = candle_preprocess(candle_data)\n",
    "        candle_data = indicator_fill(candle_data)\n",
    "        atr = candle_data.ATR.tolist()\n",
    "        fema = candle_data[\"tenkan\"].tolist()\n",
    "        #fema = candle_data[\"5_EMA\"].tolist()\n",
    "        tosima = candle_data[\"20_SMA\"].tolist()\n",
    "        kij = candle_data[\"kijun\"].tolist()\n",
    "        chaikin = candle_data[\"chaikin\"].tolist()\n",
    "        ssl_hi = candle_data[\"ssl_high\"].tolist()\n",
    "        ssl_lo = candle_data[\"ssl_low\"].tolist()\n",
    "        #candle_data = frac_diff_calc(candle_data)\n",
    "        v = df_vectorize(candle_data)\n",
    "        test_v = np.array(v)\n",
    "        #preds = model_1.predict(test_v)\n",
    "        preds = [3]\n",
    "        #probs = np.max(model_1.predict_proba(test_v),axis=1)\n",
    "        probs = [3]\n",
    "        if (close[-2] <= ssl_hi[-2] or close[-2] <= ssl_lo[-2]) and (close[-1] > ssl_hi[-1] and close[-1] > ssl_lo[-1]):\n",
    "            u = 0\n",
    "        elif (close[-2] >= ssl_hi[-2] or close[-2] >= ssl_lo[-2]) and (close[-1] < ssl_hi[-1] and close[-1] < ssl_lo[-1]):\n",
    "            u = 1\n",
    "        else:\n",
    "            u = 3\n",
    "        if u == 0:\n",
    "            p = 0\n",
    "        elif u == 1:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = 2\n",
    "        try:\n",
    "            trade_df = pd.DataFrame({\"a\":preds})\n",
    "            prob_df = pd.DataFrame({\"a\":probs})\n",
    "            ind_cross = pd.DataFrame({\"a\":[p]})\n",
    "            ind_cross.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\ind_cross_spx.csv\",index=False)\n",
    "            u_cross = pd.DataFrame({\"a\":[u]})\n",
    "            u_cross.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\u_cross_spx.csv\",index=False)\n",
    "            trade_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\trade_spx.csv\",index=False)\n",
    "            prob_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\prob_spx.csv\",index=False)\n",
    "            atr_df = pd.DataFrame({\"a\":[atr[-1]]})\n",
    "            atr_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\atr_spx.csv\",index=False)\n",
    "            close_df = pd.DataFrame({\"a\":[candle_form]})\n",
    "            close_df.to_csv(r\"C:\\Users\\91984\\AppData\\Roaming\\MetaQuotes\\Terminal\\AE925E3426D43DD22F06664D804D4525\\MQL4\\Files\\closure_spx.csv\",index=False)\n",
    "        except:\n",
    "            continue\n",
    "        close.pop(0)\n",
    "        low.pop(0)\n",
    "        high.pop(0)\n",
    "        opener.pop(0)\n",
    "        tick_adf.pop(0)\n",
    "        candle_adf.pop(0)\n",
    "        pos_run_agg.pop(0)\n",
    "        sign_agg.pop(0)\n",
    "        dur.pop(0)\n",
    "        counter -= 1\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "for f in range(10):\n",
    "    clear_output(wait=True)\n",
    "    print(f)  # use display(f) if you encounter performance issues\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if fema[-2] < tosima[-2] and fema[-1] > tosima[-1]:\n",
    "            p = 0\n",
    "        elif fema[-2] > tosima[-2] and fema[-1] < tosima[-1]:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = 2\n",
    "        \n",
    "        if fema[-2] <= kij[-2] and fema[-1] > kij[-1]:\n",
    "            u = 0\n",
    "        elif fema[-2] >= kij[-2] and fema[-1] < kij[-1]:\n",
    "            u = 1\n",
    "        if u == 0 and close[-1] > high[-27]:\n",
    "            p = 0\n",
    "        elif u == 1 and close[-1] < low[-27]:\n",
    "            p = 1\n",
    "        else:\n",
    "            p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfer = pd.read_csv(\"50_GBP_v4checkv16.csv\")\n",
    "\n",
    "can_buy = True\n",
    "can_sell = True\n",
    "sold = False\n",
    "bought = False\n",
    "sale = []\n",
    "bcount = 0\n",
    "scount = 0\n",
    "for i,j in dfer.iterrows():\n",
    "    if j.Pred == \"buy\" and can_buy:\n",
    "        sale += [\"bought\"]\n",
    "        can_buy = False\n",
    "        bought = True\n",
    "        bcount = 0\n",
    "    elif j.Pred == \"sell\" and can_sell:\n",
    "        sale += [\"sold\"]\n",
    "        can_sell = False\n",
    "        sold = True\n",
    "        scount = 0\n",
    "    else:\n",
    "        sale += [\"Ongoing\"]\n",
    "    if bcount >= 20:\n",
    "        can_buy = True\n",
    "        bought = False\n",
    "    if bought:\n",
    "        bcount += 1\n",
    "    if scount >= 20:\n",
    "        can_sell = True\n",
    "        sold = False\n",
    "    if sold:\n",
    "        scount += 1\n",
    "\n",
    "dfer[\"Sales\"] = sale\n",
    "dfer.to_csv(\"50_GBP_v4checkv16.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
